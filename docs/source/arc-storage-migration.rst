ARC Storage (Migration)
=======================


Introduction
------------

Over the last year the ARC team has been working on replacing part of the storage infrastructure behind the ARC and HTC clusters. This is necessary since the current storage infrastructure is end of life, and to meet the increasing space and performance demands. 

As a reminder - ``$DATA`` is the shared permanent storage available to projects to store research data required for (or generated by) use of the ARC clusters. ``$SCRATCH`` is the temporary storage created at the beginning of the job which can be used by programs to store temporary data shared by processes during a job run; ``$SCRATCH`` space is deleted after the job is stopped. There is a third area available to users, ``$HOME``, which (mostly) holds data required for the login process.

The new storage replaces ``$DATA`` and ``$SCRATCH`` - ``$HOME`` is unaffected.

More information on the different types of storage can be found on the ARC user guide at https://arc-user-guide.readthedocs.io/en/latest/arc-storage.html 

Migration process
-----------------

We have created all projects' and users' directories on the new storage and these can now be accessed under ``/migration/$PROJECT/$USER``. Each user is responsible for copying their own data to the new location. We would advise to copy data – not move it – as moving it takes longer, plus a copy process allows you to confirm the files were transferred successfully. 

There are two options for migration:

1) You (and your fellow project members) can copy the contents of your current ``$DATA`` area to the new ``/migration/$PROJECT/$USER`` storage, and once complete we will switch this to become ``$DATA``. Your old ``$DATA`` will then become available at ``/migration/$PROJECT/$USER`` and be read-only.

2) We can mount the new storage as a new "empty" ``$DATA`` area for a project, and you can copy your data from ``/migration/$PROJECT/$USER``. **This is the option recommended by ARC** - it allows for new data being produced in the correct place whilst old data continues to be transferred.

Regardless of which option taken, the switch is *per project* - users within projects will need to co-ordinate to ensure they are all ready for the switch to be made. It will not be possible to switch per-user data directories.

If you are a member of multiple projects, you will need to move all your data areas separately.

Please contact ‘support@arc.ox.ac.uk’ if you would like your storage area switched, or discuss those options.

How to transfer data
--------------------

There are many ways to copy files from one folder to another but not all are appropriate in this case. As mentioned above, using ``mv`` is not advisable as you do not want to remove the data from the old storage. ``cp`` is also not advisable as it is very slow. ``rsync`` is probably the best option, as it is interruptible and resumable, but may not be the fastest solution for very large trees. For very large trees, using a ``tar | tar`` solution may be faster.

The rsync solution looks like the following:

.. code-block:: shell

  cd /data/<projectname>/$USER
  rsync –avhP . /migration/<projectname>/$USER/

Alternatively, using tar can be done with the following method:

.. code-block:: shell

  cd /data/<projectname>/$USER
  tar cvf - . | tar xf - -C /migration/<projectname>/$USER/ 

These can be run from an nx session, an interactive session, or submitted as a job on the cluster. An example submission script would look something like:

.. code-block:: bash

  #!/bin/bash 
  #SBATCH --nodes=1 
  #SBATCH --ntasks-per-node=1 
  #SBATCH --cpus-per-task=2 
  #SBATCH --partition=short 
  #SBATCH --job-name=Data_migration 
  
  module purge 

  # change the value of `MYPROJECT` to the project you want to migrate
  export MYPROJECT="engs-example"

  cd /data/$MYPROJECT/$USER 
  rsync -avhP . /migration/$MYPROJECT/$USER/

Be careful when using a cluster job, and especially when copying in an interactive session; the time limit might interrupt your transfer before it is complete.

Who is responsible for migrating my data?
-----------------------------------------

Each user is responsible for transferring their data; however, the project PI or a user appointed by the project PI is responsible for gathering progress from all project users and make the decision for when the whole project should be switched from the old storage to the new. The switch from old to new has to be done on a project basis. We cannot move users individually.

How long will my data be available on the old storage after migration?
----------------------------------------------------------------------


 
If you are unable to access either of these directories, please let us know.
